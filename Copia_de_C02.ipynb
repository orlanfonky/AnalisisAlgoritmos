{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de C02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orlanfonky/AnalisisAlgoritmos/blob/master/Copia_de_C02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yndthtrg5wX",
        "outputId": "021abc13-b6dd-41bf-8af7-d9525ae6ed3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import math\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "documents = [\"Human machine interface for lab abc computer applications abc\",\n",
        "             \"A survey of user opinion of computer system response time\",\n",
        "             \"The EPS user interface management system\",\n",
        "             \"System and human system engineering testing of EPS\",\n",
        "             \"Relation of user perceived response time to error measurement\",\n",
        "             \"The generation of random binary unordered trees\",\n",
        "             \"The intersection graph of paths in trees\",\n",
        "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
        "             \"Graph minors A survey\", \n",
        "             \"Human machine interface for machine learning applications\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDkTnR6ftU3v"
      },
      "source": [
        "##Etapa de procesamiento\n",
        "vocab = [] #Vocabulario\n",
        "tok_docs = [] #Documentos procesados\n",
        "\n",
        "punt = [\".\",\",\",\":\",\"?\"]\n",
        "english_stopwords = stopwords.words(\"english\")\n",
        "\n",
        "for doc in documents:\n",
        "  word_tok = nltk.word_tokenize(doc)\n",
        "  filtered_sentence = []\n",
        "  for w in word_tok:\n",
        "    w = w.lower()\n",
        "    if w not in punt and w not in english_stopwords:\n",
        "      filtered_sentence.append(w)\n",
        "      vocab.append(w)\n",
        "\n",
        "  tok_docs.append(filtered_sentence)\n",
        "\n",
        "vocab = sorted(set(vocab))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cb77hxgvNnD",
        "outputId": "506a5839-9510-418c-87ba-a0a825ec290c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(vocab)\n",
        "print(len(vocab))\n",
        "print(tok_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['abc', 'applications', 'binary', 'computer', 'engineering', 'eps', 'error', 'generation', 'graph', 'human', 'interface', 'intersection', 'iv', 'lab', 'learning', 'machine', 'management', 'measurement', 'minors', 'opinion', 'ordering', 'paths', 'perceived', 'quasi', 'random', 'relation', 'response', 'survey', 'system', 'testing', 'time', 'trees', 'unordered', 'user', 'well', 'widths']\n",
            "36\n",
            "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications', 'abc'], ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time', 'abc'], ['eps', 'user', 'interface', 'management', 'system'], ['system', 'human', 'system', 'engineering', 'testing', 'eps'], ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'], ['generation', 'random', 'binary', 'unordered', 'trees'], ['intersection', 'graph', 'paths', 'trees'], ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'], ['graph', 'minors', 'survey'], ['human', 'machine', 'interface', 'machine', 'learning', 'applications']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BPQ-3qbv6iF"
      },
      "source": [
        "## Funci√≥n para crear el diccionario TF de cada documento\n",
        "def computeDocsTFDict(doc):\n",
        "  \"\"\" Retorna un diccionario de frecuencas con las palabras unicas del documento\"\"\" \n",
        "  TFDict = {}\n",
        "  for word in doc:\n",
        "    if word in TFDict:\n",
        "      TFDict[word] += 1\n",
        "    else:\n",
        "      TFDict[word] = 1\n",
        "\n",
        "  for word in TFDict:\n",
        "    TFDict[word] = TFDict[word] / len(doc)\n",
        "  return TFDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDH9oBEnxBWN",
        "outputId": "a25a7695-1ee6-4ff3-9138-57ba9d011fc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfDict = []\n",
        "for doc in tok_docs:\n",
        "  tfDict.append(computeDocsTFDict(doc))\n",
        "\n",
        "tfDict[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'abc': 0.25,\n",
              " 'applications': 0.125,\n",
              " 'computer': 0.125,\n",
              " 'human': 0.125,\n",
              " 'interface': 0.125,\n",
              " 'lab': 0.125,\n",
              " 'machine': 0.125}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgX8vzgxxk0H",
        "outputId": "0e5f400d-cedf-495e-e06e-a3ba153a05ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "##Calculo de IDF\n",
        "def computeWordCountDict(tfDict):\n",
        "  \"\"\" Devuelve un diccionario cuyos indices son todas las palabras del vocabulario y cuyos valores son \n",
        "  el numero de documentos donde ocurren\n",
        "  \"\"\"\n",
        "  countDict = {}\n",
        "\n",
        "  for doc in tfDict:\n",
        "    for word in doc:\n",
        "      if word in countDict:\n",
        "        countDict[word] +=1\n",
        "      else:\n",
        "        countDict[word] = 1\n",
        "  \n",
        "  return countDict\n",
        "\n",
        "countDict = computeWordCountDict(tfDict)\n",
        "countDict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'abc': 2,\n",
              " 'applications': 2,\n",
              " 'binary': 1,\n",
              " 'computer': 2,\n",
              " 'engineering': 1,\n",
              " 'eps': 2,\n",
              " 'error': 1,\n",
              " 'generation': 1,\n",
              " 'graph': 3,\n",
              " 'human': 3,\n",
              " 'interface': 3,\n",
              " 'intersection': 1,\n",
              " 'iv': 1,\n",
              " 'lab': 1,\n",
              " 'learning': 1,\n",
              " 'machine': 2,\n",
              " 'management': 1,\n",
              " 'measurement': 1,\n",
              " 'minors': 2,\n",
              " 'opinion': 1,\n",
              " 'ordering': 1,\n",
              " 'paths': 1,\n",
              " 'perceived': 1,\n",
              " 'quasi': 1,\n",
              " 'random': 1,\n",
              " 'relation': 1,\n",
              " 'response': 2,\n",
              " 'survey': 2,\n",
              " 'system': 3,\n",
              " 'testing': 1,\n",
              " 'time': 2,\n",
              " 'trees': 3,\n",
              " 'unordered': 1,\n",
              " 'user': 3,\n",
              " 'well': 1,\n",
              " 'widths': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2xNiNwyziZs",
        "outputId": "9cee2e9c-8a6d-4df4-99ab-3314cb6ec0a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Calculo del IDF\n",
        "def computeIDFDict(countDict):\n",
        "  \"\"\"Devuelve un diccionario cuyos indices son palabras y sus valores son el idf correspondiente\"\"\"\n",
        "  idfDict = {}\n",
        "  for word in countDict:\n",
        "    idfDict[word] = math.log(len(documents)/countDict[word])\n",
        "  \n",
        "  return idfDict\n",
        "\n",
        "idfDict = computeIDFDict(countDict)\n",
        "idfDict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'abc': 1.6094379124341003,\n",
              " 'applications': 1.6094379124341003,\n",
              " 'binary': 2.302585092994046,\n",
              " 'computer': 1.6094379124341003,\n",
              " 'engineering': 2.302585092994046,\n",
              " 'eps': 1.6094379124341003,\n",
              " 'error': 2.302585092994046,\n",
              " 'generation': 2.302585092994046,\n",
              " 'graph': 1.2039728043259361,\n",
              " 'human': 1.2039728043259361,\n",
              " 'interface': 1.2039728043259361,\n",
              " 'intersection': 2.302585092994046,\n",
              " 'iv': 2.302585092994046,\n",
              " 'lab': 2.302585092994046,\n",
              " 'learning': 2.302585092994046,\n",
              " 'machine': 1.6094379124341003,\n",
              " 'management': 2.302585092994046,\n",
              " 'measurement': 2.302585092994046,\n",
              " 'minors': 1.6094379124341003,\n",
              " 'opinion': 2.302585092994046,\n",
              " 'ordering': 2.302585092994046,\n",
              " 'paths': 2.302585092994046,\n",
              " 'perceived': 2.302585092994046,\n",
              " 'quasi': 2.302585092994046,\n",
              " 'random': 2.302585092994046,\n",
              " 'relation': 2.302585092994046,\n",
              " 'response': 1.6094379124341003,\n",
              " 'survey': 1.6094379124341003,\n",
              " 'system': 1.2039728043259361,\n",
              " 'testing': 2.302585092994046,\n",
              " 'time': 1.6094379124341003,\n",
              " 'trees': 1.2039728043259361,\n",
              " 'unordered': 2.302585092994046,\n",
              " 'user': 1.2039728043259361,\n",
              " 'well': 2.302585092994046,\n",
              " 'widths': 2.302585092994046}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPZzxyKG0KpL",
        "outputId": "7cf27157-4e27-4604-8269-11c84166f783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def computeDocsTFIDFDict(TFDict,idfDict):\n",
        "  \"\"\"Devuelve tf*idf\"\"\"\n",
        "  TFIDFDict = {}\n",
        "  for word in TFDict:\n",
        "    if word in idfDict:\n",
        "      TFIDFDict[word] = TFDict[word] * idfDict[word]\n",
        "\n",
        "  return TFIDFDict\n",
        "\n",
        "tfidfDict = [computeDocsTFIDFDict(doc,idfDict) for doc in tfDict]\n",
        "tfidfDict[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'abc': 0.40235947810852507,\n",
              " 'applications': 0.20117973905426254,\n",
              " 'computer': 0.20117973905426254,\n",
              " 'human': 0.15049660054074201,\n",
              " 'interface': 0.15049660054074201,\n",
              " 'lab': 0.28782313662425574,\n",
              " 'machine': 0.20117973905426254}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll0AB1KO1J9q",
        "outputId": "4e086752-ab0b-43e0-9523-44ddd8680f3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def computeTFIDFVector(doc):\n",
        "  tfidfVector = [0.0] * len(vocab)\n",
        "  for i,word in enumerate(vocab):\n",
        "    if word in doc:\n",
        "      tfidfVector[i] = doc[word]\n",
        "  return tfidfVector\n",
        "\n",
        "\n",
        "tfidfVector = [computeTFIDFVector(doc) for doc in tfidfDict]\n",
        "tfidfVector[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.3837641821656743,\n",
              " 0.26823965207235,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.20066213405432268,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.40132426810864535,\n",
              " 0.3837641821656743,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTpsj6FL3-no"
      },
      "source": [
        "def dot_product(vector_x, vector_y):\n",
        "    dot = 0.0\n",
        "    for e_x, e_y in zip(vector_x, vector_y):\n",
        "       dot += e_x * e_y\n",
        "    return dot\n",
        "\n",
        "def magnitude(vector):\n",
        "    mag = 0.0\n",
        "    for index in vector:\n",
        "        mag += math.pow(index, 2)\n",
        "    return math.sqrt(mag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37tYmYaS4ONd",
        "outputId": "0044d485-26ed-4128-dd96-671a1c5c3b34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc_similarity_0_1 = dot_product(tfidfVector[0], tfidfVector[1])/ magnitude(tfidfVector[0]) * magnitude(tfidfVector[1])\n",
        "doc_similarity_0_1\n",
        "\n",
        "\n",
        "doc_similarity_0_9 = dot_product(tfidfVector[0], tfidfVector[9])/ magnitude(tfidfVector[0]) * magnitude(tfidfVector[9])\n",
        "doc_similarity_0_9\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2656383077208393"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10rznUKc4uM3",
        "outputId": "04f76e32-ec07-4915-9d25-1a41a07f601d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### Query\n",
        "\n",
        "doc_query = \"Human Machine interface\"\n",
        "doc_query = nltk.word_tokenize(doc_query)\n",
        "\n",
        "filtered_sentence = [] \n",
        "for w in doc_query: \n",
        "    w = w.lower()\n",
        "    if w not in english_stopwords: \n",
        "        filtered_sentence.append(w)\n",
        "print(filtered_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['human', 'machine', 'interface']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOVzjokw5Wiv",
        "outputId": "60914680-e408-4d2b-decd-b555e06a3571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Paso 2: Frecuencia de palabras en el nuevo documento\n",
        "tf_doc_New = computeDocsTFDict(filtered_sentence)\n",
        "print(tf_doc_New)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'human': 0.3333333333333333, 'machine': 0.3333333333333333, 'interface': 0.3333333333333333}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z67VFc2q5e4o",
        "outputId": "b9e7e0cc-d58f-4178-a920-bb60a0db3953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Paso 3: TF-IDF\n",
        "tfidf_doc_New = computeDocsTFIDFDict(tf_doc_New,idfDict)\n",
        "print(tfidf_doc_New)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'human': 0.40132426810864535, 'machine': 0.5364793041447, 'interface': 0.40132426810864535}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0kg0njX5mqa",
        "outputId": "c10b7258-9627-4886-ed8c-864ca7593277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Paso 4: Vectorizar\n",
        "vec_doc_New = computeTFIDFVector(tfidf_doc_New)\n",
        "print(vec_doc_New)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40132426810864535, 0.40132426810864535, 0.0, 0.0, 0.0, 0.0, 0.5364793041447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aC7n8ll5xRK",
        "outputId": "7a46682e-1fbf-4dbc-c797-698255e5b2bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Paso 5: Calcular la similitud con los documentos corpus\n",
        "\n",
        "for i,doc_corpus in enumerate(tfidfVector):\n",
        "  print(\"Similitud con documento: \"+ str(i))\n",
        "  doc_similarity_doc_NEW = dot_product(tfidfVector[i], vec_doc_New)/ magnitude(tfidfVector[i]) * magnitude(vec_doc_New)\n",
        "  print(doc_similarity_doc_NEW)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similitud con documento: 0\n",
            "0.2784795810147783\n",
            "Similitud con documento: 1\n",
            "0.0\n",
            "Similitud con documento: 2\n",
            "0.10785675077577303\n",
            "Similitud con documento: 3\n",
            "0.0834628019936454\n",
            "Similitud con documento: 4\n",
            "0.0\n",
            "Similitud con documento: 5\n",
            "0.0\n",
            "Similitud con documento: 6\n",
            "0.0\n",
            "Similitud con documento: 7\n",
            "0.0\n",
            "Similitud con documento: 8\n",
            "0.0\n",
            "Similitud con documento: 9\n",
            "0.4573340091944827\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}